{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f4ec3f",
   "metadata": {},
   "source": [
    "Heart Disease Prediction by Ipsita Mishra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3741a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b3cdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the csv data to a Pandas DataFrame\n",
    "heart_data = pd.read_csv(r\"C:\\Users\\mishr\\OneDrive\\Documents\\heart disease\\heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16e48c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6b3e92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 5 rows of the dataset\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3c5b593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print last 5 rows of the dataset\n",
    "heart_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd247a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 14)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows and columns in the dataset\n",
    "heart_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1aea002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measures about the data\n",
    "heart_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89f66abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "# getting some info about the data\n",
    "heart_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e114c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    526\n",
       "0    499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of Target Variable\n",
    "heart_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1532a315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "735af45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target      1.000000\n",
      "oldpeak     0.438441\n",
      "exang       0.438029\n",
      "cp          0.434854\n",
      "thalach     0.422895\n",
      "ca          0.382085\n",
      "slope       0.345512\n",
      "thal        0.337838\n",
      "sex         0.279501\n",
      "age         0.229324\n",
      "trestbps    0.138772\n",
      "restecg     0.134468\n",
      "chol        0.099966\n",
      "fbs         0.041164\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Checking correlation between columns\n",
    "print(heart_data.corr()[\"target\"].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e72580df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows that most columns are moderately correlated with target, but 'fbs' is very weakly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72c42ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predictors = heart_data.drop(\"target\",axis=1)\n",
    "target = heart_data[\"target\"]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13c3593f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 13)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43270e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 13)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ce5e9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0074883d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29271ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Fitting\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f8df3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d75b80e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af067586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Logistic Regression is: 86.34 %\n"
     ]
    }
   ],
   "source": [
    "score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Logistic Regression is: \"+str(score_lr)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1a63bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "\n",
    "sv.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_svm = sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "45ad8587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15fd7057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Linear SVM is: 83.9 %\n"
     ]
    }
   ],
   "source": [
    "score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Linear SVM is: \"+str(score_svm)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a56108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train,Y_train)\n",
    "Y_pred_knn=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "594fa2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e9d4c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using KNN is: 72.2 %\n"
     ]
    }
   ],
   "source": [
    "score_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09b40dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_accuracy = 0\n",
    "\n",
    "\n",
    "for x in range(200):\n",
    "    dt = DecisionTreeClassifier(random_state=x)\n",
    "    dt.fit(X_train,Y_train)\n",
    "    Y_pred_dt = dt.predict(X_test)\n",
    "    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
    "    if(current_accuracy>max_accuracy):\n",
    "        max_accuracy = current_accuracy\n",
    "        best_x = x\n",
    "        \n",
    "#print(max_accuracy)\n",
    "#print(best_x)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=best_x)\n",
    "dt.fit(X_train,Y_train)\n",
    "Y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91a6281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred_dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09ad57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Decision Tree is: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0729406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b4d781ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu',input_dim=13))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c97c474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 0s 972us/step - loss: 7.4559 - accuracy: 0.5415\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 986us/step - loss: 2.7580 - accuracy: 0.6098\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.7829 - accuracy: 0.6744\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.7174 - accuracy: 0.6720\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 961us/step - loss: 1.6779 - accuracy: 0.6695\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.6306 - accuracy: 0.6732\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 980us/step - loss: 1.5809 - accuracy: 0.6732\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 968us/step - loss: 1.5300 - accuracy: 0.6732\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 988us/step - loss: 1.4861 - accuracy: 0.6768\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.4252 - accuracy: 0.6854\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 948us/step - loss: 1.3805 - accuracy: 0.6841\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 945us/step - loss: 1.3229 - accuracy: 0.6902\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.2636 - accuracy: 0.6976\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.2187 - accuracy: 0.6854\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.1677 - accuracy: 0.6854\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 997us/step - loss: 1.1164 - accuracy: 0.6915\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 957us/step - loss: 1.0790 - accuracy: 0.6988\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 947us/step - loss: 1.0395 - accuracy: 0.7000\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 924us/step - loss: 0.9941 - accuracy: 0.6902\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 947us/step - loss: 0.9452 - accuracy: 0.7146\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 949us/step - loss: 0.9048 - accuracy: 0.7098\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8734 - accuracy: 0.7085\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8268 - accuracy: 0.7098\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 995us/step - loss: 0.7957 - accuracy: 0.7159\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 874us/step - loss: 0.7658 - accuracy: 0.7073\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 905us/step - loss: 0.7344 - accuracy: 0.7159\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 964us/step - loss: 0.7035 - accuracy: 0.7256\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 915us/step - loss: 0.6802 - accuracy: 0.7171\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 880us/step - loss: 0.6589 - accuracy: 0.7146\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 911us/step - loss: 0.6377 - accuracy: 0.7183\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 948us/step - loss: 0.6155 - accuracy: 0.7244\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 874us/step - loss: 0.6005 - accuracy: 0.7329\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 925us/step - loss: 0.5826 - accuracy: 0.7305\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.5775 - accuracy: 0.7220\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 943us/step - loss: 0.5606 - accuracy: 0.7305\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 968us/step - loss: 0.5572 - accuracy: 0.7280\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 943us/step - loss: 0.5375 - accuracy: 0.7341\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.5287 - accuracy: 0.7415\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 943us/step - loss: 0.5222 - accuracy: 0.7415\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 903us/step - loss: 0.5213 - accuracy: 0.7268\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 909us/step - loss: 0.5085 - accuracy: 0.7524\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 946us/step - loss: 0.5074 - accuracy: 0.7439\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.5023 - accuracy: 0.7476\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 916us/step - loss: 0.4978 - accuracy: 0.7561\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 872us/step - loss: 0.4946 - accuracy: 0.7585\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.4896 - accuracy: 0.7573\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 907us/step - loss: 0.4902 - accuracy: 0.7573\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 896us/step - loss: 0.4849 - accuracy: 0.7610\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 924us/step - loss: 0.4829 - accuracy: 0.7659\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 994us/step - loss: 0.4803 - accuracy: 0.7622\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.4786 - accuracy: 0.7646\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 946us/step - loss: 0.4757 - accuracy: 0.7622\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 915us/step - loss: 0.4730 - accuracy: 0.7671\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 964us/step - loss: 0.4704 - accuracy: 0.7695\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.4709 - accuracy: 0.7780\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 890us/step - loss: 0.4672 - accuracy: 0.7805\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 898us/step - loss: 0.4631 - accuracy: 0.7805\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 881us/step - loss: 0.4624 - accuracy: 0.7939\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 879us/step - loss: 0.4618 - accuracy: 0.7829\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 856us/step - loss: 0.4557 - accuracy: 0.7915\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.4573 - accuracy: 0.7915\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 885us/step - loss: 0.4541 - accuracy: 0.7902\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.4513 - accuracy: 0.7951\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.4508 - accuracy: 0.7915\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 880us/step - loss: 0.4501 - accuracy: 0.8024\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.4506 - accuracy: 0.8000\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 874us/step - loss: 0.4446 - accuracy: 0.7988\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.4460 - accuracy: 0.7988\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 932us/step - loss: 0.4501 - accuracy: 0.8000\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.4403 - accuracy: 0.8085\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 958us/step - loss: 0.4380 - accuracy: 0.8000\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 900us/step - loss: 0.4375 - accuracy: 0.8037\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 983us/step - loss: 0.4332 - accuracy: 0.8073\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 913us/step - loss: 0.4304 - accuracy: 0.8110\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 979us/step - loss: 0.4284 - accuracy: 0.7951\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 904us/step - loss: 0.4365 - accuracy: 0.8024\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 990us/step - loss: 0.4325 - accuracy: 0.8073\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.4267 - accuracy: 0.8183\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.4264 - accuracy: 0.8220\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 907us/step - loss: 0.4248 - accuracy: 0.8220\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.8159\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.4246 - accuracy: 0.8207\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.4205 - accuracy: 0.8098\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 937us/step - loss: 0.4172 - accuracy: 0.8159\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 900us/step - loss: 0.4174 - accuracy: 0.8232\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 859us/step - loss: 0.4150 - accuracy: 0.8195\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 905us/step - loss: 0.4178 - accuracy: 0.8110\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 871us/step - loss: 0.4133 - accuracy: 0.8232\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 877us/step - loss: 0.4110 - accuracy: 0.8268\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 922us/step - loss: 0.4162 - accuracy: 0.8073\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 907us/step - loss: 0.4148 - accuracy: 0.8183\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8244\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.4105 - accuracy: 0.8159\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 930us/step - loss: 0.4075 - accuracy: 0.8305\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 916us/step - loss: 0.4087 - accuracy: 0.8232\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 892us/step - loss: 0.4091 - accuracy: 0.8220\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 921us/step - loss: 0.4050 - accuracy: 0.8195\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 896us/step - loss: 0.4066 - accuracy: 0.8232\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 898us/step - loss: 0.4051 - accuracy: 0.8244\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 935us/step - loss: 0.4041 - accuracy: 0.8280\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 922us/step - loss: 0.4077 - accuracy: 0.8232\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 925us/step - loss: 0.4004 - accuracy: 0.8256\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.3995 - accuracy: 0.8244\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.3985 - accuracy: 0.8354\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.3959 - accuracy: 0.8305\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.3976 - accuracy: 0.8293\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 976us/step - loss: 0.3945 - accuracy: 0.8329\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.3948 - accuracy: 0.8341\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 888us/step - loss: 0.3961 - accuracy: 0.8354\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 953us/step - loss: 0.3942 - accuracy: 0.8366\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 959us/step - loss: 0.3911 - accuracy: 0.8354\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 915us/step - loss: 0.3969 - accuracy: 0.8293\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 881us/step - loss: 0.3940 - accuracy: 0.8232\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 897us/step - loss: 0.3881 - accuracy: 0.8280\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 889us/step - loss: 0.3913 - accuracy: 0.8256\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 915us/step - loss: 0.3916 - accuracy: 0.8305\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.3883 - accuracy: 0.8256\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 890us/step - loss: 0.3897 - accuracy: 0.8415\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 864us/step - loss: 0.3928 - accuracy: 0.8268\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 868us/step - loss: 0.4027 - accuracy: 0.8207\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 916us/step - loss: 0.3879 - accuracy: 0.8280\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 881us/step - loss: 0.4067 - accuracy: 0.8098\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.3984 - accuracy: 0.8171\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.3869 - accuracy: 0.8378\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.3838 - accuracy: 0.8415\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.3874 - accuracy: 0.8354\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 937us/step - loss: 0.3854 - accuracy: 0.8390\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 945us/step - loss: 0.3933 - accuracy: 0.8366\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.3879 - accuracy: 0.8244\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 968us/step - loss: 0.3856 - accuracy: 0.8317\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.3872 - accuracy: 0.8366\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 910us/step - loss: 0.3893 - accuracy: 0.8329\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 882us/step - loss: 0.3829 - accuracy: 0.8427\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 960us/step - loss: 0.3829 - accuracy: 0.8402\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 911us/step - loss: 0.3803 - accuracy: 0.8378\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 895us/step - loss: 0.3842 - accuracy: 0.8390\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 976us/step - loss: 0.3787 - accuracy: 0.8476\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.3791 - accuracy: 0.8207\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.3819 - accuracy: 0.8366\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 882us/step - loss: 0.3854 - accuracy: 0.8354\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.3892 - accuracy: 0.8329\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 905us/step - loss: 0.3872 - accuracy: 0.8463\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.3808 - accuracy: 0.8378\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 867us/step - loss: 0.3814 - accuracy: 0.8366\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 919us/step - loss: 0.3785 - accuracy: 0.8341\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 916us/step - loss: 0.3812 - accuracy: 0.8463\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 897us/step - loss: 0.3818 - accuracy: 0.8341\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.3786 - accuracy: 0.8439\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.3778 - accuracy: 0.8476\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 957us/step - loss: 0.3838 - accuracy: 0.8439\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 929us/step - loss: 0.3807 - accuracy: 0.8427\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8427\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 922us/step - loss: 0.3808 - accuracy: 0.8439\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 952us/step - loss: 0.3787 - accuracy: 0.8341\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 952us/step - loss: 0.3793 - accuracy: 0.8439\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 914us/step - loss: 0.3741 - accuracy: 0.8439\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 923us/step - loss: 0.3799 - accuracy: 0.8378\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 907us/step - loss: 0.3776 - accuracy: 0.8463\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.3789 - accuracy: 0.8415\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 930us/step - loss: 0.3757 - accuracy: 0.8439\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.3761 - accuracy: 0.8451\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 911us/step - loss: 0.3730 - accuracy: 0.8512\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 870us/step - loss: 0.3746 - accuracy: 0.8427\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 0s 988us/step - loss: 0.3762 - accuracy: 0.8341\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 919us/step - loss: 0.3778 - accuracy: 0.8439\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 929us/step - loss: 0.3774 - accuracy: 0.8561\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 934us/step - loss: 0.3729 - accuracy: 0.8402\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 941us/step - loss: 0.3779 - accuracy: 0.8427\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 906us/step - loss: 0.3748 - accuracy: 0.8378\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 886us/step - loss: 0.3761 - accuracy: 0.8378\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 924us/step - loss: 0.3747 - accuracy: 0.8329\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 952us/step - loss: 0.3763 - accuracy: 0.8439\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 890us/step - loss: 0.3702 - accuracy: 0.8476\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 872us/step - loss: 0.3737 - accuracy: 0.8415\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 877us/step - loss: 0.3745 - accuracy: 0.8451\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 922us/step - loss: 0.3688 - accuracy: 0.8427\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 897us/step - loss: 0.3723 - accuracy: 0.8463\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 916us/step - loss: 0.3742 - accuracy: 0.8476\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.3761 - accuracy: 0.8268\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 962us/step - loss: 0.3773 - accuracy: 0.8402\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 880us/step - loss: 0.3755 - accuracy: 0.8378\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 886us/step - loss: 0.3764 - accuracy: 0.8402\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 917us/step - loss: 0.3725 - accuracy: 0.8390\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 911us/step - loss: 0.3731 - accuracy: 0.8451\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.3775 - accuracy: 0.8476\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 922us/step - loss: 0.3759 - accuracy: 0.8366\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 915us/step - loss: 0.3680 - accuracy: 0.8427\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 891us/step - loss: 0.3680 - accuracy: 0.8500\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 820us/step - loss: 0.3710 - accuracy: 0.8427\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.3743 - accuracy: 0.8341\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 905us/step - loss: 0.3760 - accuracy: 0.8415\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 890us/step - loss: 0.3694 - accuracy: 0.8524\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 920us/step - loss: 0.3691 - accuracy: 0.8549\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 884us/step - loss: 0.3748 - accuracy: 0.8439\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.3744 - accuracy: 0.8402\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 892us/step - loss: 0.3686 - accuracy: 0.8439\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8451\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 986us/step - loss: 0.3728 - accuracy: 0.8415\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 974us/step - loss: 0.3778 - accuracy: 0.8366\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 912us/step - loss: 0.3963 - accuracy: 0.8146\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 907us/step - loss: 0.3867 - accuracy: 0.8329\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 942us/step - loss: 0.3708 - accuracy: 0.8378\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 923us/step - loss: 0.3749 - accuracy: 0.8439\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 954us/step - loss: 0.3742 - accuracy: 0.8415\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 929us/step - loss: 0.3663 - accuracy: 0.8476\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 922us/step - loss: 0.3688 - accuracy: 0.8512\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 932us/step - loss: 0.3924 - accuracy: 0.8146\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 945us/step - loss: 0.3911 - accuracy: 0.8305\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 893us/step - loss: 0.3782 - accuracy: 0.8439\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8476\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 894us/step - loss: 0.3747 - accuracy: 0.8305\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 896us/step - loss: 0.3748 - accuracy: 0.8341\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 896us/step - loss: 0.3696 - accuracy: 0.8415\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 923us/step - loss: 0.3694 - accuracy: 0.8439\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 908us/step - loss: 0.3706 - accuracy: 0.8415\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 894us/step - loss: 0.3676 - accuracy: 0.8512\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 963us/step - loss: 0.3760 - accuracy: 0.8402\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 945us/step - loss: 0.3661 - accuracy: 0.8476\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 903us/step - loss: 0.3656 - accuracy: 0.8476\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 895us/step - loss: 0.3660 - accuracy: 0.8512\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 973us/step - loss: 0.3804 - accuracy: 0.8378\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.3735 - accuracy: 0.8439\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.3712 - accuracy: 0.8415\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 875us/step - loss: 0.3676 - accuracy: 0.8402\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 934us/step - loss: 0.3654 - accuracy: 0.8537\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 907us/step - loss: 0.3728 - accuracy: 0.8427\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 901us/step - loss: 0.3674 - accuracy: 0.8524\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 928us/step - loss: 0.3650 - accuracy: 0.8476\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 946us/step - loss: 0.3687 - accuracy: 0.8488\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 906us/step - loss: 0.3731 - accuracy: 0.8463\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 913us/step - loss: 0.3653 - accuracy: 0.8537\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 937us/step - loss: 0.3710 - accuracy: 0.8439\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 909us/step - loss: 0.3700 - accuracy: 0.8524\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 897us/step - loss: 0.3645 - accuracy: 0.8463\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 909us/step - loss: 0.3843 - accuracy: 0.8390\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 971us/step - loss: 0.3793 - accuracy: 0.8293\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 937us/step - loss: 0.3649 - accuracy: 0.8439\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 886us/step - loss: 0.3669 - accuracy: 0.8427\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 876us/step - loss: 0.3638 - accuracy: 0.8524\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 936us/step - loss: 0.3630 - accuracy: 0.8476\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 911us/step - loss: 0.3703 - accuracy: 0.8488\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 890us/step - loss: 0.3642 - accuracy: 0.8451\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 910us/step - loss: 0.3683 - accuracy: 0.8512\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8512\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 0s 926us/step - loss: 0.3667 - accuracy: 0.8463\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 883us/step - loss: 0.3629 - accuracy: 0.8500\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 909us/step - loss: 0.3696 - accuracy: 0.8366\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 979us/step - loss: 0.3670 - accuracy: 0.8512\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.3630 - accuracy: 0.8512\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 893us/step - loss: 0.3691 - accuracy: 0.8427\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 871us/step - loss: 0.3757 - accuracy: 0.8378\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 960us/step - loss: 0.3661 - accuracy: 0.8476\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 866us/step - loss: 0.3649 - accuracy: 0.8537\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.3675 - accuracy: 0.8451\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 944us/step - loss: 0.3850 - accuracy: 0.8451\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.3663 - accuracy: 0.8500\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 904us/step - loss: 0.3653 - accuracy: 0.8463\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 826us/step - loss: 0.3619 - accuracy: 0.8561\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 925us/step - loss: 0.3659 - accuracy: 0.8390\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 931us/step - loss: 0.3649 - accuracy: 0.8512\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 864us/step - loss: 0.3658 - accuracy: 0.8500\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 890us/step - loss: 0.3594 - accuracy: 0.8476\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 897us/step - loss: 0.3657 - accuracy: 0.8488\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 922us/step - loss: 0.3612 - accuracy: 0.8439\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 893us/step - loss: 0.3694 - accuracy: 0.8476\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 889us/step - loss: 0.3615 - accuracy: 0.8476\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 976us/step - loss: 0.3694 - accuracy: 0.8341\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 971us/step - loss: 0.3624 - accuracy: 0.8524\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 900us/step - loss: 0.3653 - accuracy: 0.8488\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.3623 - accuracy: 0.8451\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 880us/step - loss: 0.3632 - accuracy: 0.8427\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 936us/step - loss: 0.3618 - accuracy: 0.8427\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 883us/step - loss: 0.3616 - accuracy: 0.8463\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 864us/step - loss: 0.3610 - accuracy: 0.8524\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 971us/step - loss: 0.3640 - accuracy: 0.8415\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.3649 - accuracy: 0.8463\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 882us/step - loss: 0.3775 - accuracy: 0.8329\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 916us/step - loss: 0.3648 - accuracy: 0.8439\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 952us/step - loss: 0.3737 - accuracy: 0.8439\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 886us/step - loss: 0.3609 - accuracy: 0.8488\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.3689 - accuracy: 0.8390\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8561\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 956us/step - loss: 0.3610 - accuracy: 0.8537\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 891us/step - loss: 0.3609 - accuracy: 0.8549\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 925us/step - loss: 0.3599 - accuracy: 0.8500\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 924us/step - loss: 0.3736 - accuracy: 0.8439\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.3618 - accuracy: 0.8463\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 840us/step - loss: 0.3644 - accuracy: 0.8415\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 922us/step - loss: 0.3634 - accuracy: 0.8415\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 951us/step - loss: 0.3798 - accuracy: 0.8293\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 936us/step - loss: 0.3695 - accuracy: 0.8317\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8512\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 951us/step - loss: 0.3759 - accuracy: 0.8439\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 934us/step - loss: 0.3604 - accuracy: 0.8512\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.3584 - accuracy: 0.8512\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 902us/step - loss: 0.3586 - accuracy: 0.8512\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 939us/step - loss: 0.3621 - accuracy: 0.8573\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 940us/step - loss: 0.3640 - accuracy: 0.8549\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 902us/step - loss: 0.3589 - accuracy: 0.8512\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 892us/step - loss: 0.3587 - accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e5e4487f50>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2785f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 948us/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_nn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8241b789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "47512569",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = [round(x[0]) for x in Y_pred_nn]\n",
    "\n",
    "Y_pred_nn = rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b319c2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Neural Network is: 84.39 %\n"
     ]
    }
   ],
   "source": [
    "score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)\n",
    "\n",
    "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4942d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Logistic Regression is: 86.34 %\n",
      "The accuracy score achieved using Support Vector Machine is: 83.9 %\n",
      "The accuracy score achieved using K-Nearest Neighbors is: 72.2 %\n",
      "The accuracy score achieved using Decision Tree is: 100.0 %\n",
      "The accuracy score achieved using Neural Network is: 84.39 %\n"
     ]
    }
   ],
   "source": [
    "# Output final score\n",
    "scores = [score_lr,score_svm,score_knn,score_dt,score_nn]\n",
    "algorithms = [\"Logistic Regression\",\"Support Vector Machine\",\"K-Nearest Neighbors\",\"Decision Tree\",\"Neural Network\"]    \n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1e5aacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {\n",
    "                \"Logistic Regression\": accuracy_score(Y_pred_lr,Y_test),\n",
    "                \"Support Vector Machine\": accuracy_score(Y_pred_svm,Y_test),\n",
    "                \"K-Nearest Neighbors\": accuracy_score(Y_pred_knn,Y_test),\n",
    "                \"Decision Tree\": accuracy_score(Y_pred_dt,Y_test),\n",
    "                \"Neural Network\": accuracy_score(Y_pred_nn,Y_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8768abd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.8634146341463415,\n",
       " 'Support Vector Machine': 0.8390243902439024,\n",
       " 'K-Nearest Neighbors': 0.7219512195121951,\n",
       " 'Decision Tree': 1.0,\n",
       " 'Neural Network': 0.8439024390243902}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2950ca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(*zip(*model_scores.items()), color=[\"pink\", \"orange\", \"maroon\", \"yellow\", \"purple\"])\n",
    "plt.xlabel(\"Models\");\n",
    "plt.ylabel(\"Acuurary\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e36875",
   "metadata": {},
   "source": [
    "Decision tree shows 100% accuracy,\n",
    "Logistic Regression shows 86% accuracy,\n",
    "Neural Network shows 84% accuracy,\n",
    "Support Vector Machine shows 83% accuracy,\n",
    "K-Nearest Neighbors shows 72% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adad40b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
